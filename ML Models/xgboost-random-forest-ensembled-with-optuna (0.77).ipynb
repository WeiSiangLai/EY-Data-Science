{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10630346,"sourceType":"datasetVersion","datasetId":6581891},{"sourceId":10630725,"sourceType":"datasetVersion","datasetId":6582073}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.629538Z","iopub.execute_input":"2025-02-06T20:41:11.629889Z","iopub.status.idle":"2025-02-06T20:41:11.639263Z","shell.execute_reply.started":"2025-02-06T20:41:11.629860Z","shell.execute_reply":"2025-02-06T20:41:11.638345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature Engineering\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, make_scorer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\n\nimport optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.651593Z","iopub.execute_input":"2025-02-06T20:41:11.651986Z","iopub.status.idle":"2025-02-06T20:41:11.656427Z","shell.execute_reply.started":"2025-02-06T20:41:11.651949Z","shell.execute_reply":"2025-02-06T20:41:11.655197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Combine Datasets","metadata":{}},{"cell_type":"code","source":"train_density = pd.read_csv(\"/kaggle/input/buliding-density/training_data_with_density.csv\")\ntrain_density.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.657743Z","iopub.execute_input":"2025-02-06T20:41:11.658026Z","iopub.status.idle":"2025-02-06T20:41:11.692670Z","shell.execute_reply.started":"2025-02-06T20:41:11.658007Z","shell.execute_reply":"2025-02-06T20:41:11.691637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_satellite = pd.read_csv(\"/kaggle/input/satellite-data/training_data_with_satellite.csv\")\ntrain_satellite.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.693861Z","iopub.execute_input":"2025-02-06T20:41:11.694082Z","iopub.status.idle":"2025-02-06T20:41:11.736765Z","shell.execute_reply.started":"2025-02-06T20:41:11.694064Z","shell.execute_reply":"2025-02-06T20:41:11.735214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_satellite = train_satellite.drop([\"Longitude\",\"Latitude\",\"datetime\",\"UHI Index\"], axis=1)\ntrain_concat = pd.concat([train_density, train_satellite], axis = 1)\ntrain_concat.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.738236Z","iopub.execute_input":"2025-02-06T20:41:11.738522Z","iopub.status.idle":"2025-02-06T20:41:11.759821Z","shell.execute_reply.started":"2025-02-06T20:41:11.738497Z","shell.execute_reply":"2025-02-06T20:41:11.758699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_density = pd.read_csv(\"/kaggle/input/buliding-density/validation_data_with_density.csv\")\nvalidation_density.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.760697Z","iopub.execute_input":"2025-02-06T20:41:11.761010Z","iopub.status.idle":"2025-02-06T20:41:11.778702Z","shell.execute_reply.started":"2025-02-06T20:41:11.760983Z","shell.execute_reply":"2025-02-06T20:41:11.777437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_satellite = pd.read_csv(\"/kaggle/input/satellite-data/validation_data_with_satellite.csv\")\nvalidation_satellite.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.779680Z","iopub.execute_input":"2025-02-06T20:41:11.779919Z","iopub.status.idle":"2025-02-06T20:41:11.806084Z","shell.execute_reply.started":"2025-02-06T20:41:11.779901Z","shell.execute_reply":"2025-02-06T20:41:11.805186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_satellite = validation_satellite.drop([\"Longitude\",\"Latitude\",\"UHI Index\"], axis=1)\nvalidation_concat = pd.concat([validation_density, validation_satellite], axis=1)\nvalidation_concat.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.807272Z","iopub.execute_input":"2025-02-06T20:41:11.807502Z","iopub.status.idle":"2025-02-06T20:41:11.827032Z","shell.execute_reply.started":"2025-02-06T20:41:11.807484Z","shell.execute_reply":"2025-02-06T20:41:11.825611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Select features ","metadata":{}},{"cell_type":"code","source":"features = ['B01','B06','NDVI','NDBI','NDWI','LST','density']\ntrain_df = train_concat[features + [\"UHI Index\"]]\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.828276Z","iopub.execute_input":"2025-02-06T20:41:11.828561Z","iopub.status.idle":"2025-02-06T20:41:11.861971Z","shell.execute_reply.started":"2025-02-06T20:41:11.828543Z","shell.execute_reply":"2025-02-06T20:41:11.860663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Remove duplicates from training data","metadata":{}},{"cell_type":"code","source":"# Remove duplicate rows from the DataFrame based on specified columns and keep the first occurrence\nfor col in features:\n    # Check if the value is a numpy array and has more than one dimension\n    train_df[col] = train_df[col].apply(lambda x: tuple(x) if isinstance(x, np.ndarray) and x.ndim > 0 else x)\n\n# Now remove duplicates\nuhi_data = train_df.drop_duplicates(subset=features, keep='first')\nuhi_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.863439Z","iopub.execute_input":"2025-02-06T20:41:11.863691Z","iopub.status.idle":"2025-02-06T20:41:11.952198Z","shell.execute_reply.started":"2025-02-06T20:41:11.863673Z","shell.execute_reply":"2025-02-06T20:41:11.951383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uhi_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.953218Z","iopub.execute_input":"2025-02-06T20:41:11.953456Z","iopub.status.idle":"2025-02-06T20:41:11.958210Z","shell.execute_reply.started":"2025-02-06T20:41:11.953438Z","shell.execute_reply":"2025-02-06T20:41:11.957372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Resetting the index of the dataset\nuhi_data=uhi_data.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.958839Z","iopub.execute_input":"2025-02-06T20:41:11.959088Z","iopub.status.idle":"2025-02-06T20:41:11.977977Z","shell.execute_reply.started":"2025-02-06T20:41:11.959068Z","shell.execute_reply":"2025-02-06T20:41:11.976828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uhi_data.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:11.980215Z","iopub.execute_input":"2025-02-06T20:41:11.980527Z","iopub.status.idle":"2025-02-06T20:41:11.999903Z","shell.execute_reply.started":"2025-02-06T20:41:11.980502Z","shell.execute_reply":"2025-02-06T20:41:11.998813Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"# Split the data into features (X) and target (y), and then into training and testing sets\nX = uhi_data.drop(columns=['UHI Index']).values\ny = uhi_data ['UHI Index'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:12.001469Z","iopub.execute_input":"2025-02-06T20:41:12.001768Z","iopub.status.idle":"2025-02-06T20:41:12.020400Z","shell.execute_reply.started":"2025-02-06T20:41:12.001745Z","shell.execute_reply":"2025-02-06T20:41:12.019190Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature Scaling**","metadata":{}},{"cell_type":"code","source":"# Scale the training and test data using standardscaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:12.021449Z","iopub.execute_input":"2025-02-06T20:41:12.021686Z","iopub.status.idle":"2025-02-06T20:41:12.032769Z","shell.execute_reply.started":"2025-02-06T20:41:12.021668Z","shell.execute_reply":"2025-02-06T20:41:12.031747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model Training**","metadata":{}},{"cell_type":"markdown","source":"XGBoost","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid for RandomizedSearchCV\nparam_grid = {\n    'n_estimators': [200, 300, 500, 700, 900, 1000],          # Number of trees\n    'max_depth': [None, 5, 10, 30, 50, 100],           # Maximum depth of trees\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],           # Step size shrinkage\n    'subsample': [0.6, 0.8, 1.0],                      # Fraction of samples used per tree\n    'colsample_bytree': [0.6, 0.8, 1.0],               # Fraction of features used per tree\n    'min_child_weight': [1, 2, 5, 10],                 # Minimum sum of instance weight needed in a child\n    'gamma': [0, 0.1, 0.2, 0.5]                        # Minimum loss reduction required for further partitioning\n}\n\n# Define the model\nxgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n\n# Create the RandomizedSearchCV instance\nrandom_search = RandomizedSearchCV(\n    estimator=xgb_model,\n    param_distributions=param_grid,\n    n_iter=500,  # Number of random combinations to try\n    cv=5,       # 3-fold cross-validation\n    scoring=make_scorer(r2_score),\n    n_jobs=-1,  # Use all available cores\n    verbose=1,  # Print progress\n    random_state=42\n)\n\n# Perform the search\nrandom_search.fit(X_train, y_train)\n\n# Retrieve the best parameters\nbest_params = random_search.best_params_\nprint(\"Best Hyperparameters found: \", best_params)\n\n# Train the model with the best parameters\nbest_xgb = XGBRegressor(**best_params)\nbest_xgb.fit(X_train, y_train)\n\nr2_xgb = r2_score(y_test, best_xgb.predict(X_test))\n\n# Print model details\nprint(f\"Best model has {best_xgb.n_estimators} trees and max depth of {best_xgb.max_depth}.\")\nprint(f\"R^2 score: {r2_xgb}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:12.033664Z","iopub.execute_input":"2025-02-06T20:41:12.033901Z","iopub.status.idle":"2025-02-06T20:41:26.712969Z","shell.execute_reply.started":"2025-02-06T20:41:12.033879Z","shell.execute_reply":"2025-02-06T20:41:26.712044Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid for RandomizedSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300, 500, 700, 900, 1000],          # Number of trees\n    'max_depth': [None, 5, 10, 30, 50, 100],           # Maximum depth of trees\n    'min_samples_split': [2, 5, 10],             # Minimum samples required to split a node\n    'min_samples_leaf': [1, 2, 4],                # Minimum samples required in a leaf node\n    'max_features': ['sqrt', 'log2', 0.1, 0.5],  # Number of features to consider for the best split\n}\n\n\n# Define the model\nrf_model = RandomForestRegressor(random_state=42)\n\n# Create the RandomizedSearchCV instance\nrandom_search = RandomizedSearchCV(\n    estimator=rf_model,\n    param_distributions=param_grid,\n    n_iter=500,               # Number of random combinations to try\n    cv=5,                    # 3-fold cross-validation\n    scoring=make_scorer(r2_score),\n    n_jobs=-1,               # Use all available cores\n    verbose=1,               # Print progress\n    random_state=42          # Ensure reproducibility\n)\n\n# Perform the search\nrandom_search.fit(X_train, y_train)\n\n# Retrieve the best parameters\nbest_params = random_search.best_params_\nprint(\"Best Hyperparameters found: \", best_params)\n\n# Train the model with the best parameters\nbest_rf = RandomForestRegressor(**best_params)\nbest_rf.fit(X_train, y_train)\n\nr2_rf = r2_score(y_test, best_rf.predict(X_test))\n\n# Print model details\nprint(f\"Best model has {best_rf.n_estimators} trees and max depth of {best_rf.max_depth}.\")\nprint(f\"R^2 score: {r2_rf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:41:26.713541Z","iopub.execute_input":"2025-02-06T20:41:26.713730Z","iopub.status.idle":"2025-02-06T20:44:41.701608Z","shell.execute_reply.started":"2025-02-06T20:41:26.713712Z","shell.execute_reply":"2025-02-06T20:44:41.700309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ensemble XGBoost and Random Forest","metadata":{}},{"cell_type":"code","source":"# Function to compute the weighted ensemble predictions\ndef ensemble_predictions(weight, rf_preds, xgb_preds):\n    return weight * xgb_preds + (1 - weight) * rf_preds\n\n# Define the objective function for Optuna\ndef objective(trial):\n    # Suggest a weight for the XGBoost model\n    weight = trial.suggest_float('weight', 0.0, 1.0)\n    \n    # Generate predictions for both models\n    rf_preds = best_rf.predict(X_train)\n    xgb_preds = best_xgb.predict(X_train)\n    \n    # Combine predictions using the suggested weight\n    ensemble_preds = ensemble_predictions(weight, rf_preds, xgb_preds)\n    \n    # Calculate R² score for the ensemble\n    return r2_score(y_train, ensemble_preds)\n\n# Train the models on the training set\nbest_rf.fit(X_train, y_train)\nbest_xgb.fit(X_train, y_train)\n\n# Create an Optuna study to find the best weight\nstudy = optuna.create_study(direction='maximize', study_name=\"Ensemble Optimization\")\nstudy.optimize(objective, n_trials=10, show_progress_bar=True)\n\n# Retrieve the best weight\nbest_weight = study.best_params['weight']\nprint(f\"Best weight for XGBoost: {best_weight:.4f}\")\nprint(f\"Best weight for Random Forest: {1- best_weight:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:44:41.702605Z","iopub.execute_input":"2025-02-06T20:44:41.702873Z","iopub.status.idle":"2025-02-06T20:45:42.446663Z","shell.execute_reply.started":"2025-02-06T20:44:41.702855Z","shell.execute_reply":"2025-02-06T20:45:42.445607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the final ensemble model as a function\ndef ensembled_model(X):\n    rf_preds = best_rf.predict(X)\n    xgb_preds = best_xgb.predict(X)\n    return ensemble_predictions(best_weight, rf_preds, xgb_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.447374Z","iopub.execute_input":"2025-02-06T20:45:42.447580Z","iopub.status.idle":"2025-02-06T20:45:42.450923Z","shell.execute_reply.started":"2025-02-06T20:45:42.447563Z","shell.execute_reply":"2025-02-06T20:45:42.450202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Evaluate the ensemble on the test set\nfinal_r2 = r2_score(y_test, ensembled_model(X_test))\nprint(f\"Final R² score of the ensemble: {final_r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.451482Z","iopub.execute_input":"2025-02-06T20:45:42.451720Z","iopub.status.idle":"2025-02-06T20:45:42.708261Z","shell.execute_reply.started":"2025-02-06T20:45:42.451697Z","shell.execute_reply":"2025-02-06T20:45:42.707211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"validation_concat.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.709252Z","iopub.execute_input":"2025-02-06T20:45:42.709497Z","iopub.status.idle":"2025-02-06T20:45:42.731132Z","shell.execute_reply.started":"2025-02-06T20:45:42.709478Z","shell.execute_reply":"2025-02-06T20:45:42.730130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_val_data = validation_concat[features]\nsubmission_val_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.733402Z","iopub.execute_input":"2025-02-06T20:45:42.733668Z","iopub.status.idle":"2025-02-06T20:45:42.757723Z","shell.execute_reply.started":"2025-02-06T20:45:42.733648Z","shell.execute_reply":"2025-02-06T20:45:42.756576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature Scaling \nsubmission_val_data = submission_val_data.values\ntransformed_submission_data = sc.transform(submission_val_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.758875Z","iopub.execute_input":"2025-02-06T20:45:42.759158Z","iopub.status.idle":"2025-02-06T20:45:42.777137Z","shell.execute_reply.started":"2025-02-06T20:45:42.759131Z","shell.execute_reply":"2025-02-06T20:45:42.776516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Making predictions\nfinal_predictions = ensembled_model(transformed_submission_data)\nfinal_prediction_series = pd.Series(final_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.777601Z","iopub.execute_input":"2025-02-06T20:45:42.777779Z","iopub.status.idle":"2025-02-06T20:45:42.939548Z","shell.execute_reply.started":"2025-02-06T20:45:42.777762Z","shell.execute_reply":"2025-02-06T20:45:42.938932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Combining the results into dataframe\nsubmission_df = pd.DataFrame({'Longitude':validation_concat['Longitude'].values, 'Latitude':validation_concat['Latitude'].values, 'UHI Index':final_prediction_series.values})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.940161Z","iopub.execute_input":"2025-02-06T20:45:42.940465Z","iopub.status.idle":"2025-02-06T20:45:42.945500Z","shell.execute_reply.started":"2025-02-06T20:45:42.940446Z","shell.execute_reply":"2025-02-06T20:45:42.944385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Displaying the sample submission dataframe\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.946266Z","iopub.execute_input":"2025-02-06T20:45:42.946531Z","iopub.status.idle":"2025-02-06T20:45:42.976637Z","shell.execute_reply.started":"2025-02-06T20:45:42.946513Z","shell.execute_reply":"2025-02-06T20:45:42.975648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dumping the predictions into a csv file.\nsubmission_df.to_csv(\"submission.csv\",index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T20:45:42.977424Z","iopub.execute_input":"2025-02-06T20:45:42.977703Z","iopub.status.idle":"2025-02-06T20:45:42.999967Z","shell.execute_reply.started":"2025-02-06T20:45:42.977683Z","shell.execute_reply":"2025-02-06T20:45:42.998790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}